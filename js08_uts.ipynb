{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burntato/Twitter-emotion-detection-ml/blob/master/js08_uts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9DPLXQ6p8_R"
      },
      "source": [
        "Nama : Bagaseto Yudistira Fiandra Putra<br>\n",
        "NIM : 2041720244<br>\n",
        "Kelas : TI-3D<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jZG16nPp8_U"
      },
      "outputs": [],
      "source": [
        "# install packages ( google colab )\n",
        "# pip install pandas\n",
        "# pip install numpy\n",
        "# pip install matplotlib\n",
        "# pip install seaborn\n",
        "# pip install sklearn\n",
        "# pip install scipy\n",
        "# pip install statsmodels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNH-6D5Tp8_V"
      },
      "source": [
        "## Deteksi Emosi Pengguna Twitter\n",
        "\n",
        "Deteksi emosi merupakan salah satu permasalahan yang dihadapi pada ***Natural Language Processing*** (NLP). Alasanya diantaranya adalah kurangnya dataset berlabel untuk mengklasifikasikan emosi berdasarkan data twitter. Selain itu, sifat dari data twitter yang dapat memiliki banyak label emosi (***multi-class***). Manusia memiliki berbagai emosi dan sulit untuk mengumpulkan data yang cukup untuk setiap emosi. Oleh karena itu, masalah ketidakseimbangan kelas akan muncul (***class imbalance***). Pada Ujian Tengah Semester (UTS) kali ini, Anda telah disediakan dataset teks twitter yang sudah memiliki label untuk beberapa kelas emosi. Tugas utama Anda adalah membuat model yang mumpuni untuk kebutuhan klasifikasi emosi berdasarkan teks.\n",
        "\n",
        "### Informasi Data\n",
        "\n",
        "Dataset yang akan digunakan adalah ****tweet_emotion.csv***. Berikut merupakan informasi tentang dataset yang dapat membantu Anda.\n",
        "\n",
        "- Total data: 40000 data\n",
        "- Label emosi: anger, boredom, empty, enthusiasm, fun, happiness, hate, love, neutral, relief, sadness, surprise, worry\n",
        "- Jumlah data untuk setiap label tidak sama (***class imbalance***)\n",
        "- Terdapat 3 kolom = 'tweet_id', 'sentiment', 'content'\n",
        "\n",
        "### Penilaian UTS\n",
        "\n",
        "UTS akan dinilai berdasaarkan 4 proses yang akan Anda lakukan, yaitu pra pengolahan data, ektraksi fitur, pembuatan model machine learning, dan evaluasi.\n",
        "\n",
        "#### Pra Pengolahan Data\n",
        "\n",
        "> **Perhatian**\n",
        "> \n",
        "> Sebelum Anda melakukan sesuatu terhadap data Anda, pastikan data yang Anda miliki sudah \"baik\", bebas dari data yang hilang, menggunakan tipe data yang sesuai, dan sebagainya.\n",
        ">\n",
        "\n",
        "Data tweeter yang ada dapatkan merupakan sebuah data mentah, maka beberapa hal dapat Anda lakukan (namun tidak terbatas pada) yaitu,\n",
        "\n",
        "1. Case Folding\n",
        "2. Tokenizing\n",
        "3. Filtering\n",
        "4. Stemming\n",
        "\n",
        "*CATATAN: PADA DATA TWITTER TERDAPAT *MENTION* (@something) YANG ANDA HARUS TANGANI SEBELUM MASUK KE TAHAP EKSTRAKSI FITUR*\n",
        "\n",
        "#### Ekstrasi Fitur\n",
        "\n",
        "Anda dapat menggunakan beberapa metode, diantaranya\n",
        "\n",
        "1. Bag of Words (Count / TF-IDF)\n",
        "2. N-gram\n",
        "3. dan sebagainya\n",
        "\n",
        "#### Pembuatan Model\n",
        "\n",
        "Anda dibebaskan dalam memilih algoritma klasifikasi. Anda dapat menggunakan algoritma yang telah diajarkan didalam kelas atau yang lain, namun dengan catatan. Berdasarkan asas akuntabilitas pada pengembangan model machine learning, Anda harus dapat menjelaskan bagaimana model Anda dapat menghasilkan nilai tertentu.\n",
        "\n",
        "#### Evaluasi\n",
        "\n",
        "Pada proses evaluasi, minimal Anda harus menggunakan metric akurasi. Akan tetapi Anda juga dapat menambahkan metric lain seperti Recall, Precision, F1-Score, detail Confussion Metric, ataupun Area Under Curve (AUC)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfxV1UHVp8_W"
      },
      "source": [
        "### Lembar Pengerjaan\n",
        "Lembar pengerjaan dimulai dari cell dibawah ini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUge39iLp8_W"
      },
      "outputs": [],
      "source": [
        "# default usage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# data preprocessing\n",
        "import re \n",
        "\n",
        "# feature extraction ( TF-IDF )\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# model training\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# model evaluation\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhLyY18Xp8_X"
      },
      "outputs": [],
      "source": [
        "# upload tweet_emotions.csv file ke google colab\n",
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHRWTJjup8_X",
        "outputId": "52b54f6d-f3bb-4a22-e34b-9e57f7841392"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>Funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends SOON!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@dannycastillo We want to trade with someone w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tweet_id   sentiment                                            content\n",
              "0  1956967341       empty  @tiffanylue i know  i was listenin to bad habi...\n",
              "1  1956967666     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696     sadness                Funeral ceremony...gloomy friday...\n",
              "3  1956967789  enthusiasm               wants to hang out with friends SOON!\n",
              "4  1956968416     neutral  @dannycastillo We want to trade with someone w..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/tweet_emotions.csv')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6UpEHhJp8_Y"
      },
      "source": [
        "Pra pengolahan data / data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GMYBTOmp8_Y"
      },
      "source": [
        "Disini saya menggunakan metode case folding dan filtering untuk menghilangkan data yang tidak digunakan, seperti sentiment 'empty' dan tweet_id yang tidak terpakai."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIJM-sM9p8_Z",
        "outputId": "5c393aca-9e15-4243-fedb-b5946cbb2439"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1956967341</td>\n",
              "      <td>empty</td>\n",
              "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends soon!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>we want to trade with someone who has houston...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tweet_id   sentiment                                            content\n",
              "0  1956967341       empty   i know  i was listenin to bad habit earlier a...\n",
              "1  1956967666     sadness  layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696     sadness                funeral ceremony...gloomy friday...\n",
              "3  1956967789  enthusiasm               wants to hang out with friends soon!\n",
              "4  1956968416     neutral   we want to trade with someone who has houston..."
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # ini untuk menghilangkan @\n",
        "    text = re.sub(r'#', '', text) # ini untuk menghilangkan #\n",
        "    text = re.sub(r'RT[\\s]+', '', text) # ini untuk menghilangkan RT\n",
        "    text = re.sub(r'https?:\\/\\/\\S+', '', text) # ini untuk menghilangkan hyperlink\n",
        "    \n",
        "    return text\n",
        "\n",
        "df['content'] = df['content'].apply(clean_text) # implementasi fungsi clean_text\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh3ykjRCp8_Z",
        "outputId": "bdddf5f2-d9d9-4561-e97a-c35d030859ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1956967666</td>\n",
              "      <td>sadness</td>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1956967696</td>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1956967789</td>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends soon!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1956968416</td>\n",
              "      <td>neutral</td>\n",
              "      <td>we want to trade with someone who has houston...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1956968477</td>\n",
              "      <td>worry</td>\n",
              "      <td>re-pinging : why didn't you go to prom? bc my ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     tweet_id   sentiment                                            content\n",
              "1  1956967666     sadness  layin n bed with a headache  ughhhh...waitin o...\n",
              "2  1956967696     sadness                funeral ceremony...gloomy friday...\n",
              "3  1956967789  enthusiasm               wants to hang out with friends soon!\n",
              "4  1956968416     neutral   we want to trade with someone who has houston...\n",
              "5  1956968477       worry  re-pinging : why didn't you go to prom? bc my ..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[df['sentiment'] != 'empty']\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUshRMuKp8_Z",
        "outputId": "e75b4d00-3c9c-4c53-c7a7-6bafab9f05cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadness</td>\n",
              "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>funeral ceremony...gloomy friday...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>enthusiasm</td>\n",
              "      <td>wants to hang out with friends soon!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neutral</td>\n",
              "      <td>we want to trade with someone who has houston...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>worry</td>\n",
              "      <td>re-pinging : why didn't you go to prom? bc my ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment                                            content\n",
              "1     sadness  layin n bed with a headache  ughhhh...waitin o...\n",
              "2     sadness                funeral ceremony...gloomy friday...\n",
              "3  enthusiasm               wants to hang out with friends soon!\n",
              "4     neutral   we want to trade with someone who has houston...\n",
              "5       worry  re-pinging : why didn't you go to prom? bc my ..."
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop('tweet_id', axis=1)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuKTJXAep8_a",
        "outputId": "209614ad-6be7-4fe6-de3c-74af5b21d040"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['sadness', 'enthusiasm', 'neutral', 'worry', 'surprise', 'love',\n",
              "       'fun', 'hate', 'happiness', 'boredom', 'relief', 'anger'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO-GmfGVp8_a"
      },
      "source": [
        "Ekstraksi Fitur / Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51ppS887p8_a",
        "outputId": "21f96f4a-5421-47cc-851d-e071bbd653ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(39173, 1000)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000, min_df=5, max_df=0.7, stop_words='english')\n",
        "\n",
        "X = vectorizer.fit_transform(df['content']).toarray()\n",
        "\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prk93oFWp8_a",
        "outputId": "c28b32a9-844f-4011-cb22-8d19b2c11626"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(39173,)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = df['sentiment']\n",
        "\n",
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aerKyRNJp8_a"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uot_l6fpp8_b",
        "outputId": "3a7cc8f8-e492-4d60-b8ba-edc3b6a11cd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(29379, 1000)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSYeeKzQp8_b",
        "outputId": "5c22a502-9233-4922-dfab-3f6357af319c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRbEyGj-p8_b",
        "outputId": "54a02dfd-c494-47b4-e5f3-d102e96fe0f0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = MultinomialNB()\n",
        "\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw9FSiNEp8_b"
      },
      "source": [
        "Evaluasi / Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm3LhUTqp8_b",
        "outputId": "5954ae0b-5041-4051-d26f-13c31085f0e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['worry', 'neutral', 'worry', ..., 'neutral', 'love', 'neutral'],\n",
              "      dtype='<U10')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5WxhXNhp8_c",
        "outputId": "4a7e39a3-66b0-48fa-9231-bbeac7a7e42f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    1    0    0   12    0    0    0   14]\n",
            " [   0    0    0    0    1    0    0   14    0    4    0   19]\n",
            " [   0    0    0    0   24    0    7   91    0    4    1   64]\n",
            " [   0    0    0    1   85    0   23  203    0    8    0  129]\n",
            " [   0    0    0    1  374    0  115  541    1   14    0  265]\n",
            " [   0    0    0    0    5    9    4  133    0   38    0  157]\n",
            " [   0    0    0    0  174    0  281  303    2   23    1  175]\n",
            " [   0    0    0    0  144    3   64 1332    0   43    3  570]\n",
            " [   0    0    0    0   39    0   17  174    4    3    0  105]\n",
            " [   0    0    0    0   39    3   21  404    0  201    1  609]\n",
            " [   0    0    0    0   59    0   29  231    1   20    4  200]\n",
            " [   0    0    0    0   89    2   50  772    2  146    1 1088]]\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTaZQVoJp8_c",
        "outputId": "2c8d13d8-11c8-467e-9b79-78f31465ec0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       1.00      0.00      0.00        27\n",
            "     boredom       1.00      0.00      0.00        38\n",
            "  enthusiasm       1.00      0.00      0.00       191\n",
            "         fun       0.50      0.00      0.00       449\n",
            "   happiness       0.36      0.29      0.32      1311\n",
            "        hate       0.53      0.03      0.05       346\n",
            "        love       0.46      0.29      0.36       959\n",
            "     neutral       0.32      0.62      0.42      2159\n",
            "      relief       0.40      0.01      0.02       342\n",
            "     sadness       0.40      0.16      0.23      1278\n",
            "    surprise       0.36      0.01      0.01       544\n",
            "       worry       0.32      0.51      0.39      2150\n",
            "\n",
            "    accuracy                           0.34      9794\n",
            "   macro avg       0.55      0.16      0.15      9794\n",
            "weighted avg       0.39      0.34      0.29      9794\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etXneQRap8_c",
        "outputId": "80782a30-edef-4b20-e2f6-78d191f8b86e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi :  33.63 %\n"
          ]
        }
      ],
      "source": [
        "print(\"Akurasi : \", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVcwtvF0p8_c"
      },
      "source": [
        "### Dibawah adalah metode lain yang saya coba untuk menambah akurasi model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4_nwd4Hp8_c",
        "outputId": "60e58e06-b4ef-406b-b570-dba396516e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    4    2    1    8    0    1    0   11]\n",
            " [   0    0    0    0    2    2    1   14    0    8    0   11]\n",
            " [   0    0    0    0   40    1    6   83    0    6    2   53]\n",
            " [   0    0    0    6  134    3   21  160    0   16    1  108]\n",
            " [   0    0    0    5  519    2  129  420    9   21    7  199]\n",
            " [   0    0    0    0   12   59    4  119    2   33    1  116]\n",
            " [   0    0    0    2  227    1  364  224    5   26    4  106]\n",
            " [   0    0    0    2  215   10   76 1307    9   59    5  476]\n",
            " [   0    0    0    0   68    1   24  141   15    9    0   84]\n",
            " [   0    0    0    3   75   19   28  383    2  270    4  494]\n",
            " [   0    0    0    0   94    1   23  203    3   32   10  178]\n",
            " [   0    0    0    4  176   22   59  698    7  223   11  950]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       1.00      0.00      0.00        27\n",
            "     boredom       1.00      0.00      0.00        38\n",
            "  enthusiasm       1.00      0.00      0.00       191\n",
            "         fun       0.27      0.01      0.03       449\n",
            "   happiness       0.33      0.40      0.36      1311\n",
            "        hate       0.48      0.17      0.25       346\n",
            "        love       0.49      0.38      0.43       959\n",
            "     neutral       0.35      0.61      0.44      2159\n",
            "      relief       0.29      0.04      0.08       342\n",
            "     sadness       0.38      0.21      0.27      1278\n",
            "    surprise       0.22      0.02      0.03       544\n",
            "       worry       0.34      0.44      0.38      2150\n",
            "\n",
            "    accuracy                           0.36      9794\n",
            "   macro avg       0.51      0.19      0.19      9794\n",
            "weighted avg       0.37      0.36      0.32      9794\n",
            "\n",
            "Akurasi :  35.74 %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear', random_state=0)\n",
        "\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)\n",
        "\n",
        "print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "print(\"Akurasi : \", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yZki63dp8_c"
      },
      "outputs": [],
      "source": [
        "# increasing SVC accuracy by using GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "\n",
        "                {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.5, 0.1, 0.01, 0.001, 0.0001]}]\n",
        "\n",
        "grid_search = GridSearchCV(estimator = svm, param_grid = parameters, scoring = 'accuracy', cv = 10, n_jobs = 10)\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "best_parameters = grid_search.best_params_\n",
        "\n",
        "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
        "\n",
        "print(\"Best Parameters:\", best_parameters)\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(cm)\n",
        "\n",
        "print(classification_report(y_test, y_pred, zero_division=1))\n",
        "\n",
        "print(\"Akurasi : \", round(accuracy_score(y_test, y_pred) * 100, 2), \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVN04nJdp8_d",
        "outputId": "868a771f-5fc5-4671-c466-1a1fc7f5f26f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['neutral'], dtype='<U10')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predicting new tweet\n",
        "\n",
        "tweet = \"Very cool tweet\"\n",
        "\n",
        "tweet = clean_text(tweet)\n",
        "\n",
        "tweet = vectorizer.transform([tweet]).toarray()\n",
        "\n",
        "classifier.predict(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hnxjd6Dlp8_d",
        "outputId": "40f81907-74c1-4efa-dd40-7181f438feb5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['neutral', 'love', 'sadness', 'neutral'], dtype='<U10')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# predicting an array of tweets\n",
        "\n",
        "tweets = [\"Very cool tweet\", \"I am so happy\", \"I am so sad\", \"I am so angry\"]\n",
        "\n",
        "tweets = [clean_text(tweet) for tweet in tweets]\n",
        "\n",
        "tweets = vectorizer.transform(tweets).toarray()\n",
        "\n",
        "classifier.predict(tweets)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "47e86d731e077963188d400b641a1f5cee6401b89b8a1175acb1a082248e2517"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}